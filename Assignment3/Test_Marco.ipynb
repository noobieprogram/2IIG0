{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: 0.25, cross, leaky, leaky, sigmoid, 32\n",
      "Validation set total error:  0.16074178122496913\n",
      "Training set total error:  0.1504022941085922\n",
      "True positives: 40\n",
      "True negatives: 40\n",
      "False positives: 1\n",
      "False negatives: 1\n",
      "Count correct: 80\n",
      "Num epochs: 19\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "class NeuralNetwork:\n",
    "# loss: cross/mse/msa/kl/huber (https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#id14)\n",
    "# activation: sigmoid/relu/leaky/elu/hyperbolic (lecture 11, slide 39)\n",
    "    def __init__(self, num_inputs, num_hidden_1, num_hidden_2, num_outputs, loss_function = \"cross\", learning_rate=0.5, hidden_layer_1_weights = None, hidden_layer_1_activation = \"elu\", hidden_layer_1_bias = None, hidden_layer_2_weights = None, hidden_layer_2_activation = \"sigmoid\", hidden_layer_2_bias = None, output_layer_weights = None, output_layer_activation = \"sigmoid\", output_layer_bias = None):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.loss_function = loss_function\n",
    "        self.hidden_layer_1 = NeuronLayer(num_hidden_1, loss_function, hidden_layer_1_activation, hidden_layer_1_bias)\n",
    "        self.hidden_layer_2 = NeuronLayer(num_hidden_2, loss_function, hidden_layer_2_activation, hidden_layer_2_bias)\n",
    "        self.output_layer = NeuronLayer(num_outputs, loss_function, output_layer_activation, output_layer_bias)\n",
    "        self.init_weights_from_inputs_to_hidden_layer_1_neurons(hidden_layer_1_weights)\n",
    "        self.init_weights_from_hidden_layer_1_to_hidden_layer_2_neurons(hidden_layer_2_weights)\n",
    "        self.init_weights_from_hidden_layer_2_neurons_to_output_layer_neurons(output_layer_weights)\n",
    "        self.init_bias_from_inputs_to_hidden_layer_1_neurons(hidden_layer_1_bias)\n",
    "        self.init_bias_from_hidden_layer_1_to_hidden_layer_2_neurons(hidden_layer_2_bias)\n",
    "        self.init_bias_from_hidden_layer_2_neurons_to_output_layer_neurons(output_layer_bias)\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "\n",
    "    def init_weights_from_inputs_to_hidden_layer_1_neurons(self, hidden_layer_1_weights):\n",
    "        weight_num = 0\n",
    "        for h in range(len(self.hidden_layer_1.neurons)):\n",
    "            for i in range(self.num_inputs):\n",
    "                if not hidden_layer_1_weights:\n",
    "                    self.hidden_layer_1.neurons[h].weights.append(random.random()*2-1)\n",
    "                else:\n",
    "                    self.hidden_layer_1.neurons[h].weights.append(hidden_layer_1_weights[weight_num])\n",
    "                weight_num += 1\n",
    "                self.hidden_layer_1.neurons[h].gradient.append(0)\n",
    "                \n",
    "    def init_weights_from_hidden_layer_1_to_hidden_layer_2_neurons(self, hidden_layer_2_weights):\n",
    "        weight_num = 0\n",
    "        for h in range(len(self.hidden_layer_2.neurons)):\n",
    "            for i in range(len(self.hidden_layer_1.neurons)):\n",
    "                if not hidden_layer_2_weights:\n",
    "                    self.hidden_layer_2.neurons[h].weights.append(random.random()*2-1)\n",
    "                else:\n",
    "                    self.hidden_layer_2.neurons[h].weights.append(hidden_layer_2_weights[weight_num])\n",
    "                weight_num += 1\n",
    "                self.hidden_layer_2.neurons[h].gradient.append(0)\n",
    "\n",
    "    def init_weights_from_hidden_layer_2_neurons_to_output_layer_neurons(self, output_layer_weights):\n",
    "        weight_num = 0\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            for h in range(len(self.hidden_layer_2.neurons)):\n",
    "                if not output_layer_weights:\n",
    "                    self.output_layer.neurons[o].weights.append(random.random()*2-1)\n",
    "                else:\n",
    "                    self.output_layer.neurons[o].weights.append(output_layer_weights[weight_num])\n",
    "                weight_num += 1\n",
    "                self.output_layer.neurons[o].gradient.append(0)\n",
    "                \n",
    "    def init_bias_from_inputs_to_hidden_layer_1_neurons(self, hidden_layer_1_bias):\n",
    "        bias_num = 0\n",
    "        for h in range(len(self.hidden_layer_1.neurons)):\n",
    "            if not hidden_layer_1_bias:\n",
    "                self.hidden_layer_1.neurons[h].bias = random.random()*2-1\n",
    "            else:\n",
    "                self.hidden_layer_1.neurons[h].bias = hidden_layer_1_bias[bias_num]\n",
    "            bias_num += 1\n",
    "                \n",
    "    def init_bias_from_hidden_layer_1_to_hidden_layer_2_neurons(self, hidden_layer_2_bias):\n",
    "        bias_num = 0\n",
    "        for h in range(len(self.hidden_layer_2.neurons)):\n",
    "            if not hidden_layer_2_bias:\n",
    "                self.hidden_layer_2.neurons[h].bias = random.random()*2-1\n",
    "            else:\n",
    "                self.hidden_layer_2.neurons[h].bias = hidden_layer_2_bias[bias_num]\n",
    "            bias_num += 1\n",
    "\n",
    "    def init_bias_from_hidden_layer_2_neurons_to_output_layer_neurons(self, output_layer_bias):\n",
    "        bias_num = 0\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            if not output_layer_bias:\n",
    "                self.output_layer.neurons[o].bias = random.random()*2-1\n",
    "            else:\n",
    "                self.output_layer.neurons[o].bias = output_layer_bias[bias_num]\n",
    "            bias_num += 1\n",
    "\n",
    "    def inspect(self):\n",
    "        print('------')\n",
    "        print('* Inputs: {}'.format(self.num_inputs))\n",
    "        print('------')\n",
    "        print('Hidden Layer 1')\n",
    "        self.hidden_layer_1.inspect()\n",
    "        print('------')\n",
    "        print('Hidden Layer 2')\n",
    "        self.hidden_layer_2.inspect()\n",
    "        print('------')\n",
    "        print('* Output Layer')\n",
    "        self.output_layer.inspect()\n",
    "        print('------')\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        hidden_layer_1_outputs = self.hidden_layer_1.feed_forward(inputs)\n",
    "        hidden_layer_2_outputs = self.hidden_layer_2.feed_forward(hidden_layer_1_outputs)\n",
    "        return self.output_layer.feed_forward(hidden_layer_2_outputs)\n",
    "\n",
    "    def train(self, training_sets):\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            pd_errors_wrt_output_neuron_total_net_input = [0] * len(self.output_layer.neurons)\n",
    "            for o in range(len(self.output_layer.neurons)):\n",
    "                pd_errors_wrt_output_neuron_total_net_input[o] = self.output_layer.neurons[o].calculate_pd_error_wrt_total_net_input(training_outputs[o])\n",
    "                # if self.loss_function == \"mse\" or self.loss_function == \"msa\":\n",
    "                pd_errors_wrt_output_neuron_total_net_input[o]/=len(training_sets)\n",
    "            \n",
    "            pd_errors_wrt_hidden_2_neuron_total_net_input = [0] * len(self.hidden_layer_2.neurons)\n",
    "            for h in range(len(self.hidden_layer_2.neurons)):\n",
    "                d_error_wrt_hidden_2_neuron_output = 0\n",
    "                for o in range(len(self.output_layer.neurons)):\n",
    "                    d_error_wrt_hidden_2_neuron_output += pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].weights[h]\n",
    "                pd_errors_wrt_hidden_2_neuron_total_net_input[h] = d_error_wrt_hidden_2_neuron_output * self.hidden_layer_2.neurons[h].calculate_pd_total_net_input_wrt_input()\n",
    "            \n",
    "            pd_errors_wrt_hidden_1_neuron_total_net_input = [0] * len(self.hidden_layer_1.neurons)\n",
    "            for h in range(len(self.hidden_layer_1.neurons)):\n",
    "                d_error_wrt_hidden_1_neuron_output = 0\n",
    "                for o in range(len(self.hidden_layer_2.neurons)):\n",
    "                    d_error_wrt_hidden_1_neuron_output += pd_errors_wrt_hidden_2_neuron_total_net_input[o] * self.hidden_layer_2.neurons[o].weights[h]\n",
    "                pd_errors_wrt_hidden_1_neuron_total_net_input[h] = d_error_wrt_hidden_1_neuron_output * self.hidden_layer_1.neurons[h].calculate_pd_total_net_input_wrt_input()\n",
    "            \n",
    "            for o in range(len(self.output_layer.neurons)):\n",
    "                for w_ho in range(len(self.output_layer.neurons[o].weights)):\n",
    "                    if t == 0:\n",
    "                        self.output_layer.neurons[o].gradient[w_ho] = 0\n",
    "                    pd_error_wrt_weight = pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].calculate_pd_total_net_input_wrt_weight(w_ho)\n",
    "                    self.output_layer.neurons[o].gradient[w_ho] += self.LEARNING_RATE * pd_error_wrt_weight\n",
    "                if t == 0:\n",
    "                    self.output_layer.neurons[o].bias_gradient = 0\n",
    "                pd_error_wrt_bias = pd_errors_wrt_output_neuron_total_net_input[o]\n",
    "                self.output_layer.neurons[o].bias_gradient += self.LEARNING_RATE * pd_error_wrt_bias\n",
    "            \n",
    "            for h in range(len(self.hidden_layer_2.neurons)):\n",
    "                for w_hh in range(len(self.hidden_layer_2.neurons[h].weights)):\n",
    "                    if t == 0:\n",
    "                        self.hidden_layer_2.neurons[h].gradient[w_hh] = 0\n",
    "                    pd_error_wrt_weight = pd_errors_wrt_hidden_2_neuron_total_net_input[h] * self.hidden_layer_2.neurons[h].calculate_pd_total_net_input_wrt_weight(w_hh)\n",
    "                    self.hidden_layer_2.neurons[h].gradient[w_hh] += self.LEARNING_RATE * pd_error_wrt_weight\n",
    "                if t == 0:\n",
    "                    self.hidden_layer_2.neurons[h].bias_gradient = 0\n",
    "                pd_error_wrt_bias = pd_errors_wrt_hidden_2_neuron_total_net_input[h]\n",
    "                self.hidden_layer_2.neurons[h].bias_gradient += self.LEARNING_RATE * pd_error_wrt_bias\n",
    "            \n",
    "            for h in range(len(self.hidden_layer_1.neurons)):\n",
    "                for w_ih in range(len(self.hidden_layer_1.neurons[h].weights)):\n",
    "                    if t == 0:\n",
    "                        self.hidden_layer_1.neurons[h].gradient[w_ih] = 0\n",
    "                    pd_error_wrt_weight = pd_errors_wrt_hidden_1_neuron_total_net_input[h] * self.hidden_layer_1.neurons[h].calculate_pd_total_net_input_wrt_weight(w_ih)\n",
    "                    self.hidden_layer_1.neurons[h].gradient[w_ih] += self.LEARNING_RATE * pd_error_wrt_weight\n",
    "                if t == 0:\n",
    "                    self.hidden_layer_1.neurons[h].bias_gradient = 0\n",
    "                pd_error_wrt_bias = pd_errors_wrt_hidden_1_neuron_total_net_input[h]\n",
    "                self.hidden_layer_1.neurons[h].bias_gradient += self.LEARNING_RATE * pd_error_wrt_bias\n",
    "                    \n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            self.output_layer.neurons[o].bias -= self.output_layer.neurons[o].bias_gradient\n",
    "            for w_ho in range(len(self.output_layer.neurons[o].weights)):\n",
    "                self.output_layer.neurons[o].weights[w_ho] -= self.output_layer.neurons[o].gradient[w_ho]\n",
    "        \n",
    "        for h in range(len(self.hidden_layer_2.neurons)):\n",
    "            self.hidden_layer_2.neurons[h].bias -= self.hidden_layer_2.neurons[h].bias_gradient\n",
    "            for w_hh in range(len(self.hidden_layer_2.neurons[h].weights)):\n",
    "                self.hidden_layer_2.neurons[h].weights[w_hh] -= self.hidden_layer_2.neurons[h].gradient[w_hh]\n",
    "            \n",
    "        for h in range(len(self.hidden_layer_1.neurons)):\n",
    "            self.hidden_layer_1.neurons[h].bias -= self.hidden_layer_1.neurons[h].bias_gradient\n",
    "            for w_ih in range(len(self.hidden_layer_1.neurons[h].weights)):\n",
    "                self.hidden_layer_1.neurons[h].weights[w_ih] -= self.hidden_layer_1.neurons[h].gradient[w_ih]\n",
    "\n",
    "    def undo(self):\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            self.output_layer.neurons[o].bias += self.output_layer.neurons[o].bias_gradient\n",
    "            for w_ho in range(len(self.output_layer.neurons[o].weights)):\n",
    "                self.output_layer.neurons[o].weights[w_ho] += self.output_layer.neurons[o].gradient[w_ho]\n",
    "        \n",
    "        for h in range(len(self.hidden_layer_2.neurons)):\n",
    "            self.hidden_layer_2.neurons[h].bias += self.hidden_layer_2.neurons[h].bias_gradient\n",
    "            for w_hh in range(len(self.hidden_layer_2.neurons[h].weights)):\n",
    "                self.hidden_layer_2.neurons[h].weights[w_hh] += self.hidden_layer_2.neurons[h].gradient[w_hh]\n",
    "            \n",
    "        for h in range(len(self.hidden_layer_1.neurons)):\n",
    "            self.hidden_layer_1.neurons[h].bias += self.hidden_layer_1.neurons[h].bias_gradient\n",
    "            for w_ih in range(len(self.hidden_layer_1.neurons[h].weights)):\n",
    "                self.hidden_layer_1.neurons[h].weights[w_ih] += self.hidden_layer_1.neurons[h].gradient[w_ih]\n",
    "\n",
    "    def calculate_total_error(self, training_sets):\n",
    "        total_error = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                error = self.output_layer.neurons[o].calculate_error(training_outputs[o])\n",
    "                # if self.loss_function == \"mse\" or self.loss_function == \"msa\":\n",
    "                error /= len(training_sets)\n",
    "                total_error += error\n",
    "        return total_error\n",
    "    \n",
    "    def print_expected_predicted(self, training_sets):\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                print(training_outputs[o], \" \",self.output_layer.neurons[o].output)\n",
    "    \n",
    "    def count_correct(self, training_sets):\n",
    "        count = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                if (training_outputs[o] == 1 and self.output_layer.neurons[o].output >= 0.5) or (training_outputs[o] == 0 and self.output_layer.neurons[o].output < 0.5):\n",
    "                    count+=1\n",
    "        return count\n",
    "    \n",
    "    def true_positive(self, training_sets):\n",
    "        count = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                if training_outputs[o] == 1 and self.output_layer.neurons[o].output >= 0.5:\n",
    "                    count+=1\n",
    "        return count\n",
    "        \n",
    "    def true_negative(self, training_sets):\n",
    "        count = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                if training_outputs[o] == 0 and self.output_layer.neurons[o].output < 0.5:\n",
    "                    count+=1\n",
    "        return count\n",
    "    \n",
    "    def false_positive(self, training_sets):\n",
    "        count = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                if training_outputs[o] == 0 and self.output_layer.neurons[o].output >= 0.5:\n",
    "                    count+=1\n",
    "        return count\n",
    "        \n",
    "    def false_negative(self, training_sets):\n",
    "        count = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                if training_outputs[o] == 1 and self.output_layer.neurons[o].output < 0.5:\n",
    "                    count+=1\n",
    "        return count\n",
    "\n",
    "class NeuronLayer:\n",
    "    def __init__(self, num_neurons, loss_function, activation, bias):\n",
    "        self.loss_function = loss_function\n",
    "        self.activation = activation\n",
    "        self.bias = bias if bias else random.random()\n",
    "        self.neurons = []\n",
    "        for i in range(num_neurons):\n",
    "            self.neurons.append(Neuron(self.loss_function, self.activation, self.bias))\n",
    "\n",
    "    def inspect(self):\n",
    "        print('Neurons:', len(self.neurons))\n",
    "        for n in range(len(self.neurons)):\n",
    "            print(' Neuron', n)\n",
    "            for w in range(len(self.neurons[n].weights)):\n",
    "                print('  Weight:', self.neurons[n].weights[w])\n",
    "            print('  Bias:', self.bias)\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron.calculate_output(inputs))\n",
    "        return outputs\n",
    "\n",
    "    def get_outputs(self):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron.output)\n",
    "        return outputs\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, loss_function, activation, bias):\n",
    "        self.loss_function = loss_function\n",
    "        self.activation = activation\n",
    "        self.bias = bias\n",
    "        self.bias_gradient = 0\n",
    "        self.weights = []\n",
    "        self.gradient = []\n",
    "\n",
    "    def calculate_output(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = self.squash(self.calculate_total_net_input())\n",
    "        return self.output\n",
    "\n",
    "    def calculate_total_net_input(self):\n",
    "        total = 0\n",
    "        for i in range(len(self.inputs)):\n",
    "            total += self.inputs[i] * self.weights[i]\n",
    "        return total + self.bias\n",
    "\n",
    "    def squash(self, total_net_input):\n",
    "        if self.activation == \"relu\":\n",
    "            return max(0, total_net_input)\n",
    "        if self.activation == \"sigmoid\":\n",
    "            return 1 / (1 + math.exp(-total_net_input))\n",
    "        if self.activation == \"leaky\":\n",
    "            a = 0.1\n",
    "            return max(a*total_net_input, total_net_input)\n",
    "        if self.activation == \"elu\":\n",
    "            a = 0.1\n",
    "            if total_net_input <= 0:\n",
    "                return a*(math.exp(total_net_input)-1)\n",
    "            else:\n",
    "                return total_net_input\n",
    "        if self.activation == \"hyperbolic\":\n",
    "            return math.tanh(total_net_input) # return (math.exp(total_net_input)-math.exp(-total_net_input))/(math.exp(total_net_input)+math.exp(-total_net_input))\n",
    "\n",
    "    def calculate_pd_error_wrt_total_net_input(self, target_output):\n",
    "        return self.calculate_pd_error_wrt_output(target_output) * self.calculate_pd_total_net_input_wrt_input();\n",
    "\n",
    "    def calculate_error(self, target_output):\n",
    "        if self.loss_function == \"mse\":\n",
    "            return (target_output - self.output) ** 2\n",
    "        if self.loss_function == \"cross\":\n",
    "            if target_output == 1:\n",
    "                return -math.log(self.output)\n",
    "            else:\n",
    "                return -math.log(1 - self.output)\n",
    "        if self.loss_function == \"mae\":\n",
    "            return abs(self.output - target_output)\n",
    "        if self.loss_function == \"kl\":\n",
    "            return self.output * math.log(self.output / max(target_output,1e-9))\n",
    "        if self.loss_function == \"huber\":\n",
    "            d = 0.1\n",
    "            if abs(target_output - self.output) < d:\n",
    "                return 0.5 * (target_output - self.output) ** 2\n",
    "            else:\n",
    "                return d * (target_output - self.output - 0.5 * d)\n",
    "\n",
    "    def calculate_pd_error_wrt_output(self, target_output):\n",
    "        if self.loss_function == \"mse\":\n",
    "            return - 2 * target_output + 2 * self.output\n",
    "        if self.loss_function == \"cross\":\n",
    "            if target_output == 1:\n",
    "                return -1/self.output\n",
    "            else:\n",
    "                return -1/(self.output-1)\n",
    "        if self.loss_function == \"mae\":\n",
    "            if self.output > target_output:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        if self.loss_function == \"kl\":\n",
    "            return math.log(self.output / max(target_output,1e-9)) + 1\n",
    "        if self.loss_function == \"huber\":\n",
    "            d = 0.1\n",
    "            if abs(target_output - self.output) < d:\n",
    "                return - target_output + self.output\n",
    "            else:\n",
    "                return - d\n",
    "\n",
    "    def calculate_pd_total_net_input_wrt_input(self):\n",
    "        if self.activation == \"relu\":\n",
    "            if self.output >= 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        if self.activation == \"sigmoid\":\n",
    "            return self.output * (1 - self.output)\n",
    "        if self.activation == \"leaky\":\n",
    "            a = 0.1\n",
    "            if self.output >= 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return a\n",
    "        if self.activation == \"elu\":\n",
    "            a = 0.1\n",
    "            if self.output <= 0:\n",
    "                return self.output+a\n",
    "            else:\n",
    "                return 1\n",
    "        if self.activation == \"hyperbolic\":\n",
    "            return 1-self.output*self.output\n",
    "\n",
    "    def calculate_pd_total_net_input_wrt_weight(self, index):\n",
    "        return self.inputs[index]\n",
    "\n",
    "df = pd.read_excel('HW3train.xlsx')\n",
    "x0 = minmax_scale(df['X_0'].tolist())\n",
    "x1 = minmax_scale(df['X_1'].tolist())\n",
    "y = df['y'].tolist()\n",
    "training_sets = []\n",
    "for i in range(len(x0)):\n",
    "    training_sets.append([[x0[i],x1[i]],[y[i]]])\n",
    "\n",
    "df = pd.read_excel('HW3validate.xlsx')\n",
    "x0 = minmax_scale(df['X_0'].tolist())\n",
    "x1 = minmax_scale(df['X_1'].tolist())\n",
    "y = df['y'].tolist()\n",
    "validation_sets = []\n",
    "for i in range(len(x0)):\n",
    "    validation_sets.append([[x0[i],x1[i]],[y[i]]])\n",
    "\n",
    "y_train = []\n",
    "y_eval = []\n",
    "x_epochs = []\n",
    "params = [0.25, \"cross\", \"leaky\", \"leaky\", \"sigmoid\"]\n",
    "\n",
    "nn = NeuralNetwork(2, 10, 10, 1, learning_rate=params[0], loss_function=params[1], hidden_layer_1_activation=params[2], hidden_layer_2_activation=params[3], output_layer_activation=params[4])\n",
    "prev_error = 2\n",
    "error = 1\n",
    "iteration = 0\n",
    "epochs = 0\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "if BATCH_SIZE > 0:\n",
    "    while True:\n",
    "        nn.train(training_sets[BATCH_SIZE*iterations:BATCH_SIZE+BATCH_SIZE*iterations])\n",
    "        y_train.append(nn.calculate_total_error(training_sets))\n",
    "        y_eval.append(nn.calculate_total_error(validation_sets))\n",
    "        x_epochs.append(epochs)\n",
    "        if nn.calculate_total_error(training_sets) < 0.15:\n",
    "            break\n",
    "        iterations += 1\n",
    "        if iterations % (math.ceil(len(training_sets) / BATCH_SIZE)) == 0:\n",
    "            iterations = 0\n",
    "            epochs += 1\n",
    "else:\n",
    "    while True:\n",
    "        nn.train(training_sets)\n",
    "        error = nn.calculate_total_error(training_sets)\n",
    "        y_train.append(error)\n",
    "        y_eval.append(nn.calculate_total_error(validation_sets))\n",
    "        x_epochs.append(iteration)\n",
    "        if error < 0.1:\n",
    "            break\n",
    "        iteration += 1\n",
    "        epochs += 1\n",
    "        if iteration == 1000:\n",
    "            break\n",
    "plots(\"Cross-Entropy\")\n",
    "nn.undo()\n",
    "\n",
    "print(\"Configuration: {}, {}, {}, {}, {}, {}\".format(params[0], params[1],params[2],params[3],params[4], BATCH_SIZE))\n",
    "print(\"Validation set total error: \", nn.calculate_total_error(validation_sets))\n",
    "print(\"Training set total error: \", nn.calculate_total_error(training_sets))\n",
    "# nn.print_expected_predicted(validation_sets)\n",
    "print(\"True positives:\",nn.true_positive(validation_sets))\n",
    "print(\"True negatives:\",nn.true_negative(validation_sets))\n",
    "print(\"False positives:\",nn.false_positive(validation_sets))\n",
    "print(\"False negatives:\",nn.false_negative(validation_sets))\n",
    "print(\"Count correct:\",nn.count_correct(validation_sets))\n",
    "print(\"Num epochs:\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(loss_fun: str):\n",
    "    plt.figure(figsize=(7.5,4))\n",
    "    plt.plot(x_epochs, y_train, label='Training')\n",
    "    plt.plot(x_epochs, y_eval, label='Validation')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(loss_fun)\n",
    "\n",
    "    plt.title(\"Plot of '{}' over training and validation data\".format(loss_fun))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig('fig1.png', dpi = 300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

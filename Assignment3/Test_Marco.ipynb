{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "class NeuralNetwork:\n",
    "# loss: cross/mse/msa/kl/huber (https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#id14)\n",
    "# activation: sigmoid/relu/leaky/elu/hyperbolic (lecture 11, slide 39)\n",
    "    def __init__(self, num_inputs, num_hidden_1, num_hidden_2, num_outputs, loss_function = \"cross\", learning_rate=0.5, hidden_layer_1_weights = None, hidden_layer_1_activation = \"elu\", hidden_layer_1_bias = None, hidden_layer_2_weights = None, hidden_layer_2_activation = \"sigmoid\", hidden_layer_2_bias = None, output_layer_weights = None, output_layer_activation = \"sigmoid\", output_layer_bias = None):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.loss_function = loss_function\n",
    "        self.hidden_layer_1 = NeuronLayer(num_hidden_1, loss_function, hidden_layer_1_activation, hidden_layer_1_bias)\n",
    "        self.hidden_layer_2 = NeuronLayer(num_hidden_2, loss_function, hidden_layer_2_activation, hidden_layer_2_bias)\n",
    "        self.output_layer = NeuronLayer(num_outputs, loss_function, output_layer_activation, output_layer_bias)\n",
    "        self.init_weights_from_inputs_to_hidden_layer_1_neurons(hidden_layer_1_weights)\n",
    "        self.init_weights_from_hidden_layer_1_to_hidden_layer_2_neurons(hidden_layer_2_weights)\n",
    "        self.init_weights_from_hidden_layer_2_neurons_to_output_layer_neurons(output_layer_weights)\n",
    "        self.init_bias_from_inputs_to_hidden_layer_1_neurons(hidden_layer_1_bias)\n",
    "        self.init_bias_from_hidden_layer_1_to_hidden_layer_2_neurons(hidden_layer_2_bias)\n",
    "        self.init_bias_from_hidden_layer_2_neurons_to_output_layer_neurons(output_layer_bias)\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "\n",
    "    def init_weights_from_inputs_to_hidden_layer_1_neurons(self, hidden_layer_1_weights):\n",
    "        weight_num = 0\n",
    "        for h in range(len(self.hidden_layer_1.neurons)):\n",
    "            for i in range(self.num_inputs):\n",
    "                if not hidden_layer_1_weights:\n",
    "                    self.hidden_layer_1.neurons[h].weights.append(random.random()*2-1)\n",
    "                else:\n",
    "                    self.hidden_layer_1.neurons[h].weights.append(hidden_layer_1_weights[weight_num])\n",
    "                weight_num += 1\n",
    "                self.hidden_layer_1.neurons[h].gradient.append(0)\n",
    "                \n",
    "    def init_weights_from_hidden_layer_1_to_hidden_layer_2_neurons(self, hidden_layer_2_weights):\n",
    "        weight_num = 0\n",
    "        for h in range(len(self.hidden_layer_2.neurons)):\n",
    "            for i in range(len(self.hidden_layer_1.neurons)):\n",
    "                if not hidden_layer_2_weights:\n",
    "                    self.hidden_layer_2.neurons[h].weights.append(random.random()*2-1)\n",
    "                else:\n",
    "                    self.hidden_layer_2.neurons[h].weights.append(hidden_layer_2_weights[weight_num])\n",
    "                weight_num += 1\n",
    "                self.hidden_layer_2.neurons[h].gradient.append(0)\n",
    "\n",
    "    def init_weights_from_hidden_layer_2_neurons_to_output_layer_neurons(self, output_layer_weights):\n",
    "        weight_num = 0\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            for h in range(len(self.hidden_layer_2.neurons)):\n",
    "                if not output_layer_weights:\n",
    "                    self.output_layer.neurons[o].weights.append(random.random()*2-1)\n",
    "                else:\n",
    "                    self.output_layer.neurons[o].weights.append(output_layer_weights[weight_num])\n",
    "                weight_num += 1\n",
    "                self.output_layer.neurons[o].gradient.append(0)\n",
    "                \n",
    "    def init_bias_from_inputs_to_hidden_layer_1_neurons(self, hidden_layer_1_bias):\n",
    "        bias_num = 0\n",
    "        for h in range(len(self.hidden_layer_1.neurons)):\n",
    "            if not hidden_layer_1_bias:\n",
    "                self.hidden_layer_1.neurons[h].bias = random.random()*2-1\n",
    "            else:\n",
    "                self.hidden_layer_1.neurons[h].bias = hidden_layer_1_bias[bias_num]\n",
    "            bias_num += 1\n",
    "                \n",
    "    def init_bias_from_hidden_layer_1_to_hidden_layer_2_neurons(self, hidden_layer_2_bias):\n",
    "        bias_num = 0\n",
    "        for h in range(len(self.hidden_layer_2.neurons)):\n",
    "            if not hidden_layer_2_bias:\n",
    "                self.hidden_layer_2.neurons[h].bias = random.random()*2-1\n",
    "            else:\n",
    "                self.hidden_layer_2.neurons[h].bias = hidden_layer_2_bias[bias_num]\n",
    "            bias_num += 1\n",
    "\n",
    "    def init_bias_from_hidden_layer_2_neurons_to_output_layer_neurons(self, output_layer_bias):\n",
    "        bias_num = 0\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            if not output_layer_bias:\n",
    "                self.output_layer.neurons[o].bias = random.random()*2-1\n",
    "            else:\n",
    "                self.output_layer.neurons[o].bias = output_layer_bias[bias_num]\n",
    "            bias_num += 1\n",
    "\n",
    "    def inspect(self):\n",
    "        print('------')\n",
    "        print('* Inputs: {}'.format(self.num_inputs))\n",
    "        print('------')\n",
    "        print('Hidden Layer 1')\n",
    "        self.hidden_layer_1.inspect()\n",
    "        print('------')\n",
    "        print('Hidden Layer 2')\n",
    "        self.hidden_layer_2.inspect()\n",
    "        print('------')\n",
    "        print('* Output Layer')\n",
    "        self.output_layer.inspect()\n",
    "        print('------')\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        hidden_layer_1_outputs = self.hidden_layer_1.feed_forward(inputs)\n",
    "        hidden_layer_2_outputs = self.hidden_layer_2.feed_forward(hidden_layer_1_outputs)\n",
    "        return self.output_layer.feed_forward(hidden_layer_2_outputs)\n",
    "\n",
    "    def train(self, training_sets):\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            pd_errors_wrt_output_neuron_total_net_input = [0] * len(self.output_layer.neurons)\n",
    "            for o in range(len(self.output_layer.neurons)):\n",
    "                pd_errors_wrt_output_neuron_total_net_input[o] = self.output_layer.neurons[o].calculate_pd_error_wrt_total_net_input(training_outputs[o])\n",
    "                # if self.loss_function == \"mse\" or self.loss_function == \"msa\":\n",
    "                pd_errors_wrt_output_neuron_total_net_input[o]/=len(training_sets)\n",
    "            \n",
    "            pd_errors_wrt_hidden_2_neuron_total_net_input = [0] * len(self.hidden_layer_2.neurons)\n",
    "            for h in range(len(self.hidden_layer_2.neurons)):\n",
    "                d_error_wrt_hidden_2_neuron_output = 0\n",
    "                for o in range(len(self.output_layer.neurons)):\n",
    "                    d_error_wrt_hidden_2_neuron_output += pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].weights[h]\n",
    "                pd_errors_wrt_hidden_2_neuron_total_net_input[h] = d_error_wrt_hidden_2_neuron_output * self.hidden_layer_2.neurons[h].calculate_pd_total_net_input_wrt_input()\n",
    "            \n",
    "            pd_errors_wrt_hidden_1_neuron_total_net_input = [0] * len(self.hidden_layer_1.neurons)\n",
    "            for h in range(len(self.hidden_layer_1.neurons)):\n",
    "                d_error_wrt_hidden_1_neuron_output = 0\n",
    "                for o in range(len(self.hidden_layer_2.neurons)):\n",
    "                    d_error_wrt_hidden_1_neuron_output += pd_errors_wrt_hidden_2_neuron_total_net_input[o] * self.hidden_layer_2.neurons[o].weights[h]\n",
    "                pd_errors_wrt_hidden_1_neuron_total_net_input[h] = d_error_wrt_hidden_1_neuron_output * self.hidden_layer_1.neurons[h].calculate_pd_total_net_input_wrt_input()\n",
    "            \n",
    "            for o in range(len(self.output_layer.neurons)):\n",
    "                for w_ho in range(len(self.output_layer.neurons[o].weights)):\n",
    "                    if t == 0:\n",
    "                        self.output_layer.neurons[o].gradient[w_ho] = 0\n",
    "                    pd_error_wrt_weight = pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].calculate_pd_total_net_input_wrt_weight(w_ho)\n",
    "                    self.output_layer.neurons[o].gradient[w_ho] += self.LEARNING_RATE * pd_error_wrt_weight\n",
    "                if t == 0:\n",
    "                    self.output_layer.neurons[o].bias_gradient = 0\n",
    "                pd_error_wrt_bias = pd_errors_wrt_output_neuron_total_net_input[o]\n",
    "                self.output_layer.neurons[o].bias_gradient += self.LEARNING_RATE * pd_error_wrt_bias\n",
    "            \n",
    "            for h in range(len(self.hidden_layer_2.neurons)):\n",
    "                for w_hh in range(len(self.hidden_layer_2.neurons[h].weights)):\n",
    "                    if t == 0:\n",
    "                        self.hidden_layer_2.neurons[h].gradient[w_hh] = 0\n",
    "                    pd_error_wrt_weight = pd_errors_wrt_hidden_2_neuron_total_net_input[h] * self.hidden_layer_2.neurons[h].calculate_pd_total_net_input_wrt_weight(w_hh)\n",
    "                    self.hidden_layer_2.neurons[h].gradient[w_hh] += self.LEARNING_RATE * pd_error_wrt_weight\n",
    "                if t == 0:\n",
    "                    self.hidden_layer_2.neurons[h].bias_gradient = 0\n",
    "                pd_error_wrt_bias = pd_errors_wrt_hidden_2_neuron_total_net_input[h]\n",
    "                self.hidden_layer_2.neurons[h].bias_gradient += self.LEARNING_RATE * pd_error_wrt_bias\n",
    "            \n",
    "            for h in range(len(self.hidden_layer_1.neurons)):\n",
    "                for w_ih in range(len(self.hidden_layer_1.neurons[h].weights)):\n",
    "                    if t == 0:\n",
    "                        self.hidden_layer_1.neurons[h].gradient[w_ih] = 0\n",
    "                    pd_error_wrt_weight = pd_errors_wrt_hidden_1_neuron_total_net_input[h] * self.hidden_layer_1.neurons[h].calculate_pd_total_net_input_wrt_weight(w_ih)\n",
    "                    self.hidden_layer_1.neurons[h].gradient[w_ih] += self.LEARNING_RATE * pd_error_wrt_weight\n",
    "                if t == 0:\n",
    "                    self.hidden_layer_1.neurons[h].bias_gradient = 0\n",
    "                pd_error_wrt_bias = pd_errors_wrt_hidden_1_neuron_total_net_input[h]\n",
    "                self.hidden_layer_1.neurons[h].bias_gradient += self.LEARNING_RATE * pd_error_wrt_bias\n",
    "                    \n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            self.output_layer.neurons[o].bias -= self.output_layer.neurons[o].bias_gradient\n",
    "            for w_ho in range(len(self.output_layer.neurons[o].weights)):\n",
    "                self.output_layer.neurons[o].weights[w_ho] -= self.output_layer.neurons[o].gradient[w_ho]\n",
    "        \n",
    "        for h in range(len(self.hidden_layer_2.neurons)):\n",
    "            self.hidden_layer_2.neurons[h].bias -= self.hidden_layer_2.neurons[h].bias_gradient\n",
    "            for w_hh in range(len(self.hidden_layer_2.neurons[h].weights)):\n",
    "                self.hidden_layer_2.neurons[h].weights[w_hh] -= self.hidden_layer_2.neurons[h].gradient[w_hh]\n",
    "            \n",
    "        for h in range(len(self.hidden_layer_1.neurons)):\n",
    "            self.hidden_layer_1.neurons[h].bias -= self.hidden_layer_1.neurons[h].bias_gradient\n",
    "            for w_ih in range(len(self.hidden_layer_1.neurons[h].weights)):\n",
    "                self.hidden_layer_1.neurons[h].weights[w_ih] -= self.hidden_layer_1.neurons[h].gradient[w_ih]\n",
    "\n",
    "    def undo(self):\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            self.output_layer.neurons[o].bias += self.output_layer.neurons[o].bias_gradient\n",
    "            for w_ho in range(len(self.output_layer.neurons[o].weights)):\n",
    "                self.output_layer.neurons[o].weights[w_ho] += self.output_layer.neurons[o].gradient[w_ho]\n",
    "        \n",
    "        for h in range(len(self.hidden_layer_2.neurons)):\n",
    "            self.hidden_layer_2.neurons[h].bias += self.hidden_layer_2.neurons[h].bias_gradient\n",
    "            for w_hh in range(len(self.hidden_layer_2.neurons[h].weights)):\n",
    "                self.hidden_layer_2.neurons[h].weights[w_hh] += self.hidden_layer_2.neurons[h].gradient[w_hh]\n",
    "            \n",
    "        for h in range(len(self.hidden_layer_1.neurons)):\n",
    "            self.hidden_layer_1.neurons[h].bias += self.hidden_layer_1.neurons[h].bias_gradient\n",
    "            for w_ih in range(len(self.hidden_layer_1.neurons[h].weights)):\n",
    "                self.hidden_layer_1.neurons[h].weights[w_ih] += self.hidden_layer_1.neurons[h].gradient[w_ih]\n",
    "\n",
    "    def calculate_total_error(self, training_sets):\n",
    "        total_error = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                error = self.output_layer.neurons[o].calculate_error(training_outputs[o])\n",
    "                # if self.loss_function == \"mse\" or self.loss_function == \"msa\":\n",
    "                error /= len(training_sets)\n",
    "                total_error += error\n",
    "        return total_error\n",
    "    \n",
    "    def print_expected_predicted(self, training_sets):\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                print(training_outputs[o], \" \",self.output_layer.neurons[o].output)\n",
    "    \n",
    "    def count_correct(self, training_sets):\n",
    "        count = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                if (training_outputs[o] == 1 and self.output_layer.neurons[o].output >= 0.5) or (training_outputs[o] == 0 and self.output_layer.neurons[o].output < 0.5):\n",
    "                    count+=1\n",
    "        return count\n",
    "    \n",
    "    def true_positive(self, training_sets):\n",
    "        count = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                if training_outputs[o] == 1 and self.output_layer.neurons[o].output >= 0.5:\n",
    "                    count+=1\n",
    "        return count\n",
    "        \n",
    "    def true_negative(self, training_sets):\n",
    "        count = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                if training_outputs[o] == 0 and self.output_layer.neurons[o].output < 0.5:\n",
    "                    count+=1\n",
    "        return count\n",
    "    \n",
    "    def false_positive(self, training_sets):\n",
    "        count = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                if training_outputs[o] == 0 and self.output_layer.neurons[o].output >= 0.5:\n",
    "                    count+=1\n",
    "        return count\n",
    "        \n",
    "    def false_negative(self, training_sets):\n",
    "        count = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                if training_outputs[o] == 1 and self.output_layer.neurons[o].output < 0.5:\n",
    "                    count+=1\n",
    "        return count\n",
    "\n",
    "class NeuronLayer:\n",
    "    def __init__(self, num_neurons, loss_function, activation, bias):\n",
    "        self.loss_function = loss_function\n",
    "        self.activation = activation\n",
    "        self.bias = bias if bias else random.random()\n",
    "        self.neurons = []\n",
    "        for i in range(num_neurons):\n",
    "            self.neurons.append(Neuron(self.loss_function, self.activation, self.bias))\n",
    "\n",
    "    def inspect(self):\n",
    "        print('Neurons:', len(self.neurons))\n",
    "        for n in range(len(self.neurons)):\n",
    "            print(' Neuron', n)\n",
    "            for w in range(len(self.neurons[n].weights)):\n",
    "                print('  Weight:', self.neurons[n].weights[w])\n",
    "            print('  Bias:', self.bias)\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron.calculate_output(inputs))\n",
    "        return outputs\n",
    "\n",
    "    def get_outputs(self):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron.output)\n",
    "        return outputs\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, loss_function, activation, bias):\n",
    "        self.loss_function = loss_function\n",
    "        self.activation = activation\n",
    "        self.bias = bias\n",
    "        self.bias_gradient = 0\n",
    "        self.weights = []\n",
    "        self.gradient = []\n",
    "\n",
    "    def calculate_output(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = self.squash(self.calculate_total_net_input())\n",
    "        return self.output\n",
    "\n",
    "    def calculate_total_net_input(self):\n",
    "        total = 0\n",
    "        for i in range(len(self.inputs)):\n",
    "            total += self.inputs[i] * self.weights[i]\n",
    "        return total + self.bias\n",
    "\n",
    "    def squash(self, total_net_input):\n",
    "        if self.activation == \"relu\":\n",
    "            return max(0, total_net_input)\n",
    "        if self.activation == \"sigmoid\":\n",
    "            return 1 / (1 + math.exp(-total_net_input))\n",
    "        if self.activation == \"leaky\":\n",
    "            a = 0.1\n",
    "            return max(a*total_net_input, total_net_input)\n",
    "        if self.activation == \"elu\":\n",
    "            a = 0.1\n",
    "            if total_net_input <= 0:\n",
    "                return a*(math.exp(total_net_input)-1)\n",
    "            else:\n",
    "                return total_net_input\n",
    "        if self.activation == \"hyperbolic\":\n",
    "            return math.tanh(total_net_input) # return (math.exp(total_net_input)-math.exp(-total_net_input))/(math.exp(total_net_input)+math.exp(-total_net_input))\n",
    "\n",
    "    def calculate_pd_error_wrt_total_net_input(self, target_output):\n",
    "        return self.calculate_pd_error_wrt_output(target_output) * self.calculate_pd_total_net_input_wrt_input();\n",
    "\n",
    "    def calculate_error(self, target_output):\n",
    "        if self.loss_function == \"mse\":\n",
    "            return (target_output - self.output) ** 2\n",
    "        if self.loss_function == \"cross\":\n",
    "            if target_output == 1:\n",
    "                return -math.log(self.output)\n",
    "            else:\n",
    "                return -math.log(1 - self.output)\n",
    "        if self.loss_function == \"mae\":\n",
    "            return abs(self.output - target_output)\n",
    "        if self.loss_function == \"kl\":\n",
    "            return self.output * math.log(self.output / max(target_output,1e-9))\n",
    "        if self.loss_function == \"huber\":\n",
    "            d = 0.1\n",
    "            if abs(target_output - self.output) < d:\n",
    "                return 0.5 * (target_output - self.output) ** 2\n",
    "            else:\n",
    "                return d * (target_output - self.output - 0.5 * d)\n",
    "\n",
    "    def calculate_pd_error_wrt_output(self, target_output):\n",
    "        if self.loss_function == \"mse\":\n",
    "            return - 2 * target_output + 2 * self.output\n",
    "        if self.loss_function == \"cross\":\n",
    "            if target_output == 1:\n",
    "                return -1/self.output\n",
    "            else:\n",
    "                return -1/(self.output-1)\n",
    "        if self.loss_function == \"mae\":\n",
    "            if self.output > target_output:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        if self.loss_function == \"kl\":\n",
    "            return math.log(self.output / max(target_output,1e-9)) + 1\n",
    "        if self.loss_function == \"huber\":\n",
    "            d = 0.1\n",
    "            if abs(target_output - self.output) < d:\n",
    "                return - target_output + self.output\n",
    "            else:\n",
    "                return - d\n",
    "\n",
    "    def calculate_pd_total_net_input_wrt_input(self):\n",
    "        if self.activation == \"relu\":\n",
    "            if self.output >= 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        if self.activation == \"sigmoid\":\n",
    "            return self.output * (1 - self.output)\n",
    "        if self.activation == \"leaky\":\n",
    "            a = 0.1\n",
    "            if self.output >= 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return a\n",
    "        if self.activation == \"elu\":\n",
    "            a = 0.1\n",
    "            if self.output <= 0:\n",
    "                return self.output+a\n",
    "            else:\n",
    "                return 1\n",
    "        if self.activation == \"hyperbolic\":\n",
    "            return 1-self.output*self.output\n",
    "\n",
    "    def calculate_pd_total_net_input_wrt_weight(self, index):\n",
    "        return self.inputs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: 0.25, cross, leaky, leaky, sigmoid, 32\n",
      "Validation set total error:  0.16123488766270874\n",
      "Training set total error:  0.15951137048680158\n",
      "True positives: 38\n",
      "True negatives: 39\n",
      "False positives: 2\n",
      "False negatives: 3\n",
      "Count correct: 77\n",
      "Num epochs: 26\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('HW3train.xlsx')\n",
    "x0 = minmax_scale(df['X_0'].tolist())\n",
    "x1 = minmax_scale(df['X_1'].tolist())\n",
    "y = df['y'].tolist()\n",
    "training_sets = []\n",
    "for i in range(len(x0)):\n",
    "    training_sets.append([[x0[i],x1[i]],[y[i]]])\n",
    "\n",
    "df = pd.read_excel('HW3validate.xlsx')\n",
    "x0 = minmax_scale(df['X_0'].tolist())\n",
    "x1 = minmax_scale(df['X_1'].tolist())\n",
    "y = df['y'].tolist()\n",
    "validation_sets = []\n",
    "for i in range(len(x0)):\n",
    "    validation_sets.append([[x0[i],x1[i]],[y[i]]])\n",
    "\n",
    "y_train = []\n",
    "y_eval = []\n",
    "x_epochs = []\n",
    "params = [0.25, \"cross\", \"leaky\", \"leaky\", \"sigmoid\"]\n",
    "\n",
    "nn = NeuralNetwork(2, 10, 10, 1, learning_rate=params[0], loss_function=params[1], hidden_layer_1_activation=params[2], hidden_layer_2_activation=params[3], output_layer_activation=params[4])\n",
    "prev_error = 2\n",
    "error = 1\n",
    "iteration = 0\n",
    "epochs = 0\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "if BATCH_SIZE > 0:\n",
    "    while True:\n",
    "        nn.train(training_sets[BATCH_SIZE*iteration:BATCH_SIZE+BATCH_SIZE*iteration])\n",
    "        y_train.append(nn.calculate_total_error(training_sets))\n",
    "        y_eval.append(nn.calculate_total_error(validation_sets))\n",
    "        x_epochs.append(epochs)\n",
    "        if nn.calculate_total_error(training_sets) < 0.15:\n",
    "            break\n",
    "        iteration += 1\n",
    "        if iteration % (math.ceil(len(training_sets) / BATCH_SIZE)) == 0:\n",
    "            iteration = 0\n",
    "            epochs += 1\n",
    "else:\n",
    "    while True:\n",
    "        nn.train(training_sets)\n",
    "        error = nn.calculate_total_error(training_sets)\n",
    "        y_train.append(error)\n",
    "        y_eval.append(nn.calculate_total_error(validation_sets))\n",
    "        x_epochs.append(iteration)\n",
    "        if error < 0.15:\n",
    "            break\n",
    "        iteration += 1\n",
    "        epochs += 1\n",
    "        if iteration == 1000:\n",
    "            break\n",
    "plots(\"Cross-Entropy\")\n",
    "nn.undo()\n",
    "\n",
    "print(\"Configuration: {}, {}, {}, {}, {}, {}\".format(params[0], params[1],params[2],params[3],params[4], BATCH_SIZE))\n",
    "print(\"Validation set total error: \", nn.calculate_total_error(validation_sets))\n",
    "print(\"Training set total error: \", nn.calculate_total_error(training_sets))\n",
    "# nn.print_expected_predicted(validation_sets)\n",
    "print(\"True positives:\",nn.true_positive(validation_sets))\n",
    "print(\"True negatives:\",nn.true_negative(validation_sets))\n",
    "print(\"False positives:\",nn.false_positive(validation_sets))\n",
    "print(\"False negatives:\",nn.false_negative(validation_sets))\n",
    "print(\"Count correct:\",nn.count_correct(validation_sets))\n",
    "print(\"Num epochs:\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plots(loss_fun: str):\n",
    "    plt.figure(figsize=(7.5,4))\n",
    "    plt.plot(x_epochs, y_train, label='Training')\n",
    "    plt.plot(x_epochs, y_eval, label='Validation')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(loss_fun)\n",
    "\n",
    "    plt.title(\"Plot of '{}' over training and validation data\".format(loss_fun))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig('fig1.png', dpi = 300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
